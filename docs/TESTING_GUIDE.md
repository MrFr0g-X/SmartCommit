# Testing Guide

## Overview

This guide explains the testing strategy and test suite for SmartCommit Phase 3.

## Test Suite Structure

The main test file is `test_phase3.py` which contains 32 comprehensive tests organized into 7 groups:

```
[1/7] Input Validation         - 6 tests
[2/7] Hallucination Severity   - 5 tests
[3/7] Confidence Levels        - 5 tests
[4/7] Safety Warnings          - 3 tests
[5/7] Usage Recommendations    - 4 tests
[6/7] Audit Logging            - 5 tests
[7/7] Output Sanitization      - 3 tests
```

## Running Tests

### Full Test Suite
```bash
python test_phase3.py
```

Expected output: **32/32 tests passing (100% pass rate)**

### Individual Test Groups
```bash
# Run only input validation tests
python -m pytest test_phase3.py::TestInputValidation -v

# Run only hallucination tests
python -m pytest test_phase3.py::TestHallucinationSeverity -v
```

## Test Coverage

### Input Validation Tests
Verify that the system properly handles:
- Empty diffs (should reject)
- Extremely large files (>10MB - should reject)
- Too many lines (>5000 lines - should reject)
- Malformed diff format (should reject)
- Sensitive data patterns (API keys, passwords - should flag)
- Rate limiting (max 100 requests/hour)

### Hallucination Severity Tests
Test all 5 severity levels:
- **NONE**: Clean commit, no hallucinations
- **LOW**: <10% ungrounded tokens (acceptable)
- **MEDIUM**: 10-25% ungrounded tokens (review recommended)
- **HIGH**: 25-50% ungrounded tokens (blocked)
- **CRITICAL**: >50% ungrounded tokens (blocked)

### Confidence Level Tests
Test 4 confidence ratings:
- **HIGH**: Quality score â‰¥ 0.7
- **MEDIUM**: Quality score 0.4-0.7
- **LOW**: Quality score 0.2-0.4
- **VERY_LOW**: Quality score < 0.2

### Audit Logging Tests
Verify that all operations are logged:
- Request metadata (timestamp, request_id, endpoint)
- Diff characteristics (size, line count)
- Generation results (message length, quality score)
- Safety assessment (hallucination detected, severity, confidence)
- Performance metrics (execution time in milliseconds)

## Test Results

### Phase 3 Test Coverage
- **Total Tests**: 32
- **Passing**: 32
- **Pass Rate**: 100%
- **Code Coverage**: 100% for `api/safety.py` and `api/audit_log.py`

### Performance Benchmarks
- Input validation: <10ms
- Safety guardrails: <50ms overhead
- Audit logging: <5ms overhead
- Total overhead: <2% of response time

## Continuous Integration

Tests should be run:
- Before every commit to main branch
- On all pull requests
- After any changes to core modules

## Known Issues & Limitations

None currently. All 32 tests passing with 100% coverage.

## Future Testing Priorities

1. Load testing with concurrent requests
2. Integration tests with live Gemini API
3. End-to-end UI tests with Streamlit
4. Performance regression testing
5. Security penetration testing
