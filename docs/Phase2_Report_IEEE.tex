% IEEE Conference Paper Template
\documentclass[conference]{IEEEtran}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{url}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{SmartCommit: AI-Based Commit Message Generation with Hallucination Detection}

\author{\IEEEauthorblockN{Hothifa Hamdan, Jilan Ismail, Youssef Mahmoud, Mariam Zakary}
\IEEEauthorblockA{\textit{Faculty of Engineering} \\
\textit{Zewail City of Science and Technology}\\
Cairo, Egypt \\
\{hothifa.hamdan, jilan.ismail, youssef.mahmoud, mariam.zakary\}@zewailcity.edu.eg}}

\maketitle

\begin{abstract}
We present SmartCommit, an AI-based system for automatic generation and quality evaluation of git commit messages. This Phase 2 report describes our working prototype implementation, experimental baseline evaluation on 170 commit samples, and early results analysis. Our system integrates Google Gemini 2.0 Flash API for message generation with a multi-metric evaluation framework including BLEU-4, ROUGE-L, semantic similarity, and hallucination detection. Baseline results show ROUGE-L of 46.62\%, semantic similarity of 0.18, but zero BLEU-4 score and 77.6\% hallucination rate, reflecting challenges in zero-shot large language model approaches. Iterative prompt engineering improvements yielded 65.4\% increase in semantic similarity, 35.3\% reduction in hallucination rate, and 34.4\% improvement in overall quality score. We analyze error patterns, categorize hallucination types, and identify key limitations requiring fine-tuning and context-aware approaches in Phase 3.
\end{abstract}

\begin{IEEEkeywords}
commit message generation, large language models, hallucination detection, software engineering, prompt engineering
\end{IEEEkeywords}

\section{Introduction}

\subsection{Problem Statement}
Writing descriptive commit messages is a critical but time-consuming aspect of software development. Studies show that 35-40\% of commit messages are trivial or uninformative \cite{jiang2017}, leading to reduced code maintainability and team collaboration efficiency. Manual message writing is inconsistent, especially under time pressure, and often lacks coverage of all changed functions or files.

\subsection{Objectives}
This Phase 2 work aims to: (1) implement a working prototype integrating AI model, evaluation metrics, and user interface; (2) establish baseline performance on a representative commit dataset; (3) identify limitations through hallucination and error analysis; (4) validate feasibility of LLM-based commit message generation; and (5) inform Phase 3 improvements through systematic evaluation.

\subsection{Research Questions}
\begin{itemize}
    \item \textbf{RQ1:} Can zero-shot large language models generate semantically meaningful commit messages?
    \item \textbf{RQ2:} What is the hallucination rate when LLMs describe code changes without fine-tuning?
    \item \textbf{RQ3:} How do iterative prompt improvements affect output quality and grounding?
    \item \textbf{RQ4:} What are the primary error categories and their root causes?
\end{itemize}

\section{Related Work}

\subsection{Commit Message Generation}
NNGen \cite{jiang2017} was the first neural approach using RNN encoder-decoder, achieving BLEU $\sim$14. CommitGen \cite{liu2018} improved this with attention mechanisms to BLEU $\sim$18-20. CommitBERT \cite{liu2020} represents current state-of-art, using BERT fine-tuned on 345K commits to achieve BLEU $\sim$23. CodeT5 \cite{wang2021} offers a pre-trained code-understanding model adaptable to commit generation.

\textbf{Gap:} Most approaches require extensive fine-tuning on commit datasets. Zero-shot LLM performance on this task remains underexplored.

\subsection{Hallucination in Code LLMs}
CodeXGLUE \cite{lu2021} benchmark shows LLMs hallucinate API names and function signatures. Recent work on grounding techniques \cite{peng2023} demonstrates retrieval-augmented generation can reduce hallucination by 40-60\%.

\section{Methodology}

\subsection{System Architecture}
Our system comprises five main components (Fig. \ref{fig:architecture}):

\begin{enumerate}
    \item \textbf{AI Model Backend:} Google Gemini 2.0 Flash API with configurable temperature and prompt templates
    \item \textbf{Evaluation Module:} BLEU-4, ROUGE-L, semantic similarity, and hallucination detection
    \item \textbf{Git Interface:} GitPython wrapper for diff extraction
    \item \textbf{Experiment Runner:} Batch processing with rate limiting (7s delays for 10 RPM API limit)
    \item \textbf{Frontend UI:} Streamlit interface with iOS 26 Liquid Glass design
\end{enumerate}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/system_architecture.png}
    \caption{SmartCommit system architecture showing component interactions}
    \label{fig:architecture}
\end{figure}

\subsection{Dataset}
We used a synthetic CommitBench-style dataset of 170 unique commit samples with balanced composition: bug fixes (33.5\%), feature additions (33.5\%), and refactoring (33.0\%). Each sample contains a git diff (unified format) and human-written reference commit message. The dataset was generated using randomized file names, function names, and change types to ensure diversity.

\subsection{Experimental Setup}
Two configurations were tested:

\textbf{Baseline:} Temperature 0.3, basic prompt with minimal guidelines

\textbf{Improved:} Temperature 0.1, enhanced prompt with 3 few-shot examples, stricter hallucination threshold (0.10 vs 0.15)

Metrics computed: BLEU-4, ROUGE-1/2/L, semantic similarity (Jaccard), hallucination detection (binary + rate), quality score (weighted combination), and generation latency.

\section{Results}

\subsection{Baseline Performance}
Table \ref{tab:baseline} shows baseline results (Experiment ID: 20251127\_001902) on 170 samples. Key observations: zero BLEU-4 indicates no exact 4-gram matches due to paraphrasing; ROUGE-L of 46.62 shows moderate lexical overlap; high hallucination rate (77.6\%) indicates significant ungrounded information.

\begin{table}[h]
\centering
\caption{Baseline System Performance}
\label{tab:baseline}
\small
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{Score} & \textbf{Std Dev} \\
\midrule
BLEU-4 & 0.00 & 0.00 \\
ROUGE-L & 46.62 & $\pm$21.89 \\
Semantic Similarity & 0.1785 & $\pm$0.1150 \\
Hallucination Rate & 77.6\% & - \\
Quality Score & 0.2158 & $\pm$0.1235 \\
Mean Latency & 690ms & - \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Improved System Performance}
Prompt engineering improvements (Experiment ID: 20251127\_005526) yielded substantial gains. ROUGE-L improved 2.8\% to 47.90; semantic similarity increased 65.4\% to 0.2952; hallucination rate reduced 35.3\% to 42.4\%; quality score improved 34.4\% to 0.2899; latency decreased 7.5\% to 639ms.

\subsection{Comparison Analysis}
Table \ref{tab:comparison} presents detailed baseline vs improved comparison. The most significant improvement was semantic similarity (+65.4\%), attributed to few-shot examples in the improved prompt. Hallucination reduction (-35.3\%) resulted from stricter grounding rules and lower temperature. BLEU-4 remained 0.00 due to synthetic dataset variance and zero-shot LLM paraphrasing behavior.

\begin{table}[h]
\centering
\caption{Baseline vs Improved System Comparison}
\label{tab:comparison}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Metric} & \textbf{Baseline} & \textbf{Improved} & \textbf{Change} & \textbf{\% Change} \\
\midrule
BLEU-4 & 0.00 & 0.00 & +0.00 & - \\
ROUGE-L & 46.62 & 47.90 & +1.28 & +2.8\% \\
Semantic Sim. & 0.1785 & 0.2952 & +0.1167 & +65.4\% \\
Hallucination & 77.6\% & 42.4\% & -35.3\% & -45.5\% \\
Quality Score & 0.2158 & 0.2899 & +0.0742 & +34.4\% \\
Latency (ms) & 690 & 639 & -52 & -7.5\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[t]
    \centering
    \includegraphics[width=0.48\textwidth]{figures/metrics_comparison.png}
    \caption{Visual comparison of baseline vs improved performance}
    \label{fig:metrics}
\end{figure}

\section{Hallucination Analysis}

\subsection{Error Categories}
Analysis of the improved system (72/170 samples, 42.4\% hallucination rate) revealed two primary error categories:

\textbf{Hallucination Errors (42.4\%):} Ungrounded tokens not present in diff, including invented function/variable names (e.g., \texttt{\_simplified\_item\_process}), wrong method names, mean ungrounded token rate: 25.94\%.

\textbf{Context Misunderstanding (57.6\%):} Described wrong operations, such as "return True" when actual change differs, or "refactor" when change is a bug fix.

\subsection{Root Cause Analysis}
\textbf{Why BLEU-4 = 0:} Zero-shot LLMs naturally paraphrase rather than match exact phrases; no exposure to conventional commit message patterns during inference; model prioritizes natural language fluency over template matching.

\textbf{Why High Hallucination:} Lack of strict grounding constraints in baseline prompt; model trained on general text, not code-specific grounding; diff provides limited context compared to full file view; temperature 0.3 allows creative token sampling.

\section{Discussion}

\subsection{Research Questions Answered}

\textbf{RQ1:} Partially. ROUGE-L of 46.62 and semantic similarity of 0.30 (improved) show the model captures general intent, but lacks precision and grounding.

\textbf{RQ2:} 42.4\% of messages (improved system) contain hallucinated information with mean rate 25.94\%. This is significantly higher than acceptable for production (<10\%).

\textbf{RQ3:} Yes, significantly. Semantic similarity improved 65.4\%, hallucination reduced 35.3\%, quality score increased 34.4\%. However, BLEU-4 challenges persist without fine-tuning.

\textbf{RQ4:} Hallucination errors (42.4\%) and context misunderstanding (57.6\%) dominate, caused by lack of code-specific training and grounding mechanisms.

\subsection{Limitations}
Technical limitations include Jaccard similarity not being true semantic similarity (SBERT needed), potential over-flagging of technical terms in hallucination detection, small dataset (170 samples) limiting generalization, and Python-only scope.

Methodological limitations: synthetic dataset may not reflect real commit diversity; reference messages are synthetic, not human-written; no human evaluation; single model tested.

\subsection{Comparison to State-of-Art}
CommitBERT (SOTA) achieves BLEU $\sim$23 with fine-tuning on 345K commits. Our baseline achieves BLEU 0 zero-shot on 170 samples. The gap analysis shows fine-tuning accounts for $\sim$23 BLEU point difference. However, our ROUGE-L (47.90) suggests potential for improvement with tuning.

\section{Phase 3 Plan}

High priority enhancements: (1) install Sentence-BERT for true semantic similarity; (2) fine-tune on CommitBench (345K samples) targeting BLEU 15-20; (3) implement post-processing filter to remove hallucinated sentences; (4) enforce conventional commit format (fix:, feat:, etc.).

Expected impact with fine-tuning: BLEU-4: 0 $\rightarrow$ 15-25; Hallucination: 42.4\% $\rightarrow$ 20-30\%; Quality Score: 0.29 $\rightarrow$ 0.65-0.75.

\section{Conclusion}

We successfully implemented and evaluated a working prototype for AI-based commit message generation. Baseline results reveal significant challenges in zero-shot LLM approaches, primarily ungrounded information and lack of pattern matching. Iterative prompt engineering yielded substantial improvements in semantic similarity (+65.4\%), hallucination reduction (-35.3\%), and quality (+34.4\%), demonstrating value of prompt optimization but fundamental need for fine-tuning. Error analysis identified hallucination and context misunderstanding as dominant failure modes. Phase 3 will address limitations through fine-tuning on 345K commits, RAG-based context enhancement, and SBERT semantic similarity. This work establishes a solid foundation and validates the feasibility of LLM-based commit generation with appropriate training.


\begin{thebibliography}{00}
\bibitem{jiang2017} S. Jiang et al., ``Automatically Generating Commit Messages from Diffs using Neural Machine Translation,'' \textit{ASE}, 2017.
\bibitem{liu2018} Z. Liu et al., ``Neural-Machine-Translation-Based Commit Message Generation,'' \textit{ICSE}, 2018.
\bibitem{liu2020} S. Liu et al., ``CommitBERT: Commit Message Generation Using Pre-Trained Programming Language Model,'' \textit{ASE}, 2020.
\bibitem{wang2021} Y. Wang et al., ``CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation,'' \textit{EMNLP}, 2021.
\bibitem{lu2021} S. Lu et al., ``CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation,'' \textit{NeurIPS}, 2021.
\bibitem{peng2023} S. Peng et al., ``Towards Making the Most of ChatGPT for Code Generation,'' \textit{arXiv:2305.04118}, 2023.
\end{thebibliography}

\end{document}
